{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first3 = pd.read_csv(\"C:\\\\Users\\\\talfi\\\\.spyder-py3\\\\first3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "  #creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    #creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    #marking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    #using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#logreg = LogisticRegression()\n",
    "X_train, X_test, y_train ,y_test = train_test_split(\n",
    "    first3.drop(columns='Company'),\n",
    "    first3['Company'],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=first3['Company']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8073333333333332\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=12, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8081333333333334\tDecisionTreeClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=55), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8073333333333332\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=12, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8081333333333334\tDecisionTreeClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=55), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-3\t0.8146666666666667\tDecisionTreeClassifier(SelectPercentile(SelectPercentile(input_matrix, SelectPercentile__percentile=55), SelectPercentile__percentile=46), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8073333333333332\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=12, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8081333333333334\tDecisionTreeClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=55), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-3\t0.8146666666666667\tDecisionTreeClassifier(SelectPercentile(SelectPercentile(input_matrix, SelectPercentile__percentile=55), SelectPercentile__percentile=46), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.808\tDecisionTreeClassifier(CombineDFs(input_matrix, input_matrix), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=7, DecisionTreeClassifier__min_samples_split=14)\n",
      "\n",
      "-2\t0.8146666666666667\tDecisionTreeClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=15), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8088\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=9, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8146666666666667\tDecisionTreeClassifier(SelectPercentile(input_matrix, SelectPercentile__percentile=15), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=8, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "AUC score: {0: 0.5, 1: 0.5}\n",
      "\n",
      "Best pipeline steps:\n",
      "1. SelectPercentile(percentile=15)\n",
      "2. DecisionTreeClassifier(max_depth=8, min_samples_leaf=17, min_samples_split=7,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    verbosity=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light'\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "tpot_auc_score = roc_auc_score_multiclass(y_test, tpot.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nAUC score:',tpot_auc_score)\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=8, min_samples_leaf=17, min_samples_split=7,\n",
    "                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "dtc.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
